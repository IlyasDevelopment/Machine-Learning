{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " \"HW04_sgd.ipynb\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snxSUWXD7q_p"
      },
      "source": [
        "## Домашнее задание по неделе 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-8OLsAV7wrQ"
      },
      "source": [
        "Как было рассказано на лекции, стохастический градиентый спуск сходится быстрее, чем полный, хотя и менее стабильно. В этом задании вам предлагается реализовать стохастический градиентный спуск и сравнить его с точным вычислением весов линейной модели по скорости работы и значению метрики качества."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgQyWw5o7Nej"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGD1wQgMruJw"
      },
      "source": [
        "### Задание 0\n",
        "\n",
        "Реализуйте класс ```LinearRegressionSGD``` c обучением и и применением линейной регрессии, построенной с помощью стохастического градиентного спуска, с заданным интерфейсом."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZxdV27R9-uc"
      },
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "class LinearRegressionSGD(BaseEstimator):\n",
        "    def __init__(self, epsilon=1e-4, max_steps=100, w0=None, alpha=1e-4):\n",
        "        \"\"\"\n",
        "        epsilon: разница для нормы изменения весов \n",
        "        max_steps: максимальное количество шагов в градиентном спуске\n",
        "        w0: np.array (d,) - начальные веса\n",
        "        alpha: шаг обучения\n",
        "        \"\"\"\n",
        "        self.epsilon = epsilon\n",
        "        self.max_steps = max_steps\n",
        "        self.w0 = w0\n",
        "        self.alpha = alpha\n",
        "        self.w = None\n",
        "        self.w_history = []\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array (l, d)\n",
        "        y: np.array (l)\n",
        "        ---\n",
        "        output: self\n",
        "        \"\"\"\n",
        "        l, d = X.shape # l - кол-во объектов, d - признаков\n",
        "\n",
        "        if self.w0 is None:\n",
        "          self.w0 = np.zeros(d)\n",
        "\n",
        "        self.w = self.w0\n",
        "\n",
        "        for step in range(self.max_steps):\n",
        "          self.w_history.append(self.w)\n",
        "          w_new = self.w - self.alpha * self.calc_gradient(X, y)\n",
        "          if np.linalg.norm(w_new - self.w) < self.epsilon:\n",
        "            break\n",
        "          self.w = w_new\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        X: np.array (l, d)\n",
        "        ---\n",
        "        output: np.array (l)\n",
        "        \"\"\"\n",
        "        if self.w is None:\n",
        "          raise Exception('Not trained yet')\n",
        "\n",
        "        l, d = X.shape\n",
        "        y_pred = []\n",
        "\n",
        "        for i in range(l):\n",
        "          y_pred.append(np.dot(X[i], self.w))\n",
        "        \n",
        "        return np.array(y_pred)\n",
        "    \n",
        "    def calc_gradient(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array (l, d)\n",
        "        y: np.array (l)\n",
        "        ---\n",
        "        output: np.array (d)\n",
        "        \"\"\"\n",
        "        l, d = X.shape\n",
        "        gradient = []\n",
        "        i = np.random.randint(0, l)\n",
        "\n",
        "        for j in range(d):\n",
        "          dL = 2/l * X[i][j] * (np.dot(self.w, X[i]) - y[i])\n",
        "          gradient.append(dL)\n",
        "\n",
        "\n",
        "        return np.array(gradient)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNOm9-bXpdT3"
      },
      "source": [
        "Проверять работу мы будем на имеющемся в sklearn наборе данных boston: в нём нужно по информации о доме предсказать его стоимость."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c24JCwes9-pe"
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = load_boston()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(np.array(X), y, test_size=0.3, random_state=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eIJwWnInXnr"
      },
      "source": [
        "### Задание 1\n",
        "\n",
        "Метрикой качества в нашей задаче будет MAPE - Mean Absolute Percentage Error. Реализуйте её с заданным интефейсом и вычислите \n",
        "```MAPE(y_test, y_0)```, где ```y_0 = (mean(y_test), mean(y_test), ...)```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znoDavxyuLsi"
      },
      "source": [
        "def MAPE(y_true, y_pred):\n",
        "    \"\"\"\n",
        "        y_true: np.array (l)\n",
        "        y_pred: np.array (l)\n",
        "        ---\n",
        "        output: float [0, +inf)\n",
        "    \"\"\"\n",
        "    # mape = np.mean(np.abs((y_true - y_pred)/y_true)) * 100\n",
        "    y_error = y_pred - y_true # рассчитайте вектор ошибок\n",
        "    y_error_abs = [abs(i) for i in y_error] # рассчитайте вектор модуля ошибок\n",
        "    perc_error_abs = y_error_abs/ y_true # рассчитайте вектор относительных ошибок\n",
        "    mape = (sum(perc_error_abs) / len(y_true)) * 100\n",
        "    return mape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayuOLJC6H_wq",
        "outputId": "424f2284-1bd5-4481-922e-86532e60666b"
      },
      "source": [
        "!pip show scikit-learn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: scikit-learn\n",
            "Version: 0.24.1\n",
            "Summary: A set of python modules for machine learning and data mining\n",
            "Home-page: http://scikit-learn.org\n",
            "Author: None\n",
            "Author-email: None\n",
            "License: new BSD\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: scipy, numpy, threadpoolctl, joblib\n",
            "Required-by: yellowbrick, umap-learn, textgenrnn, sklearn, sklearn-pandas, pynndescent, mlxtend, lucid, lightgbm, librosa, imbalanced-learn, fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6mTAykeojwp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f162f4e4-e84b-4757-ffd1-75489ca628e4"
      },
      "source": [
        "import sklearn\n",
        "\n",
        "y_0 = []\n",
        "for i in range(len(y_test)):\n",
        "  y_0.append(np.mean(y_test))\n",
        "\n",
        "MAPE(y_test, y_0)\n",
        "# sklearn.metrics.mean_absolute_percentage_error(y_test, y_0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37.415882976840955"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G23vyx9F5bjt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nNy2ITxuMKf"
      },
      "source": [
        "### Задание 2 \n",
        "\n",
        "Обучите ```LinearRegressionSGD``` с базовыми параметрами на тренировочном наборе данных (```X_train```, ```y_train```), сделайте предсказание на тестовых данных ```X_test```, записав результат в переменную ```y_pred_sgd```  и вычислите ошибку MAPE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BIHwAwUvB-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddaa8ca4-6dc2-4316-bfcd-1c6972a68424"
      },
      "source": [
        "sgd = LinearRegressionSGD() # epsilon=1e-4/len(y_test), alpha=1e-4/len(y_test)\n",
        "\n",
        "sgd.fit(X_train, y_train)\n",
        "\n",
        "y_pred_sgd = sgd.predict(X_test)\n",
        "\n",
        "MAPE(y_test, y_pred_sgd)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38.20685540623259"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWappMdMtIPV"
      },
      "source": [
        "### Задание 3\n",
        "\n",
        "Вычислите веса по точной формуле, используя ```X_train``` и ```y_train```; предскажите с их помощью целевую переменную на ```X_test```, записав результат в переменную ```y_pred_lr``` и вычислите ошибку MAPE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjMUlPje9-k0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eab6ca20-03de-45ba-80d3-7bee40c8817b"
      },
      "source": [
        "w = np.dot(np.linalg.inv(np.dot(X_train.T, X_train)), (np.dot(X_train.T, y_train)))\n",
        "\n",
        "y_pred_lr = np.dot(X_test, w) \n",
        "\n",
        "MAPE(y_test, y_pred_lr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18.953134816376206"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}